{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "99eb1258-c71a-4b82-8e59-982d15f09fd0",
    "_uuid": "9238ff111736f6dafa907a02fed5bf5f59e4fc27"
   },
   "source": [
    "# Music Recommendation\n",
    "\n",
    "In this notebook I create and train the model for this dataset https://www.kaggle.com/c/kkbox-music-recommendation-challenge/data. The aim is to predict if a user will listen a song for a second time within a month after the first time. Based on this information a recommendation system can be built.\n",
    "\n",
    "#### The structure of the data:\n",
    "\n",
    "**train.csv**\n",
    "\n",
    "msno: user id\n",
    "song_id: song id\n",
    "source_system_tab: the name of the tab where the event was triggered. System tabs are used to categorize KKBOX mobile apps functions. For example, tab my library contains functions to manipulate the local storage, and tab search contains functions relating to search.\n",
    "source_screen_name: name of the layout a user sees.\n",
    "source_type: an entry point a user first plays music on mobile apps. An entry point could be album, online-playlist, song .. etc.\n",
    "target: this is the target variable. target=1 means there are recurring listening event(s) triggered within a month after the user’s very first observable listening event, target=0 otherwise .\n",
    "\n",
    "**songs.csv**\n",
    "\n",
    "The songs. Note that data is in unicode.\n",
    "\n",
    "song_id\n",
    "song_length: in ms\n",
    "genre_ids: genre category. Some songs have multiple genres and they are separated by |\n",
    "artist_name\n",
    "composer\n",
    "lyricist\n",
    "language\n",
    "\n",
    "**members.csv**\n",
    "\n",
    "user information.\n",
    "\n",
    "msno\n",
    "city\n",
    "bd: age. Note: this column has outlier values, please use your judgement.\n",
    "gender\n",
    "registered_via: registration method\n",
    "registration_init_time: format %Y%m%d\n",
    "expiration_date: format %Y%m%d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3cb501c4-dadc-4c3d-9034-dae9f36cfca1",
    "_uuid": "8401fb3bb4c7a53a8c58e48db4113d1d402a8111"
   },
   "source": [
    "#### Load Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "3cb501c4-dadc-4c3d-9034-dae9f36cfca1",
    "_uuid": "8401fb3bb4c7a53a8c58e48db4113d1d402a8111"
   },
   "outputs": [],
   "source": [
    "#1 for data preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#2 for building a model \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "083ab3c8-e2fc-472b-af26-fedf97c82dbc",
    "_uuid": "ed268cdb9426fa20e5b4e523b2c14fe9ca6a7741"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "083ab3c8-e2fc-472b-af26-fedf97c82dbc",
    "_uuid": "ed268cdb9426fa20e5b4e523b2c14fe9ca6a7741"
   },
   "source": [
    "#### Downloading data. 1% of Data is used to speed up execution. Can also be run on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "323c09d3-4908-478a-abc9-8d7be6669620",
    "_uuid": "9a273952dd0ac2715f48aa16a90278bba6021a1e"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# 1% sample of items\n",
    "df = df.sample(frac=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join data of songs, members and events (train) into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "133c555c-7927-4e60-ad75-f2fabb82b948",
    "_uuid": "e35704b25cc37bbc9e231e681cbd627a95aeadbc"
   },
   "outputs": [],
   "source": [
    "# Load and join songs data\n",
    "songs = pd.read_csv('./data/songs.csv')\n",
    "df = pd.merge(df, songs, on='song_id', how='left')\n",
    "del songs\n",
    "\n",
    "# Load and join songs data\n",
    "members = pd.read_csv('./data/members.csv')\n",
    "df = pd.merge(df, members, on='msno', how='left')\n",
    "del members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check how much data is missing in each column in %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "941e45d6-2ef6-499c-9bef-240e9f309701",
    "_uuid": "c2b3d2b26bfa4e8186203b3a85b49dcf8b5404ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msno                       0.000000\n",
       "song_id                    0.000000\n",
       "source_system_tab          0.316830\n",
       "source_screen_name         5.883028\n",
       "source_type                0.265021\n",
       "target                     0.000000\n",
       "song_length                0.000000\n",
       "genre_ids                  1.636679\n",
       "artist_name                0.000000\n",
       "composer                  29.285176\n",
       "lyricist                  75.176901\n",
       "language                   0.001356\n",
       "city                       0.000000\n",
       "bd                         0.000000\n",
       "gender                    67.041775\n",
       "registered_via             0.000000\n",
       "registration_init_time     0.000000\n",
       "expiration_date            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()/df.count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check how the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_type</th>\n",
       "      <th>target</th>\n",
       "      <th>song_length</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>composer</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>language</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>expiration_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z75En2y0vBrKTwJ3taDYLpu/xDQLnYcEGKgxaqVtPwM=</td>\n",
       "      <td>kThrcfiM7bay5gCTGaV8vkS7S1eDJAduRy08b8NzQa4=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>0</td>\n",
       "      <td>231758</td>\n",
       "      <td>465</td>\n",
       "      <td>小樂 (吳思賢) (Ben Wu)</td>\n",
       "      <td>范瑋琪</td>\n",
       "      <td>王雅君</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20130328</td>\n",
       "      <td>20170930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1GUmx833Bi+TTIX7/gLutzwqFssO/fYQKfeoMsVKMI=</td>\n",
       "      <td>uwGAfDt1trs7aTxUM5DPYRtalQY/IPszFbRPgayilDQ=</td>\n",
       "      <td>discover</td>\n",
       "      <td>Search</td>\n",
       "      <td>song</td>\n",
       "      <td>0</td>\n",
       "      <td>263941</td>\n",
       "      <td>458</td>\n",
       "      <td>楊丞琳 (Rainie Yang)</td>\n",
       "      <td>Xiao-Leng</td>\n",
       "      <td>Ai-Li-Si</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>20150801</td>\n",
       "      <td>20170918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1fe9d48tkl74qwJJ3UGq5wJG2NEBoRI36YMYqTrTplo=</td>\n",
       "      <td>/56EZoEb7TAm0G8GLJpA2Uzgg6QiJcYDwvI08I+w8JA=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-library</td>\n",
       "      <td>1</td>\n",
       "      <td>272811</td>\n",
       "      <td>465</td>\n",
       "      <td>陳潔儀 (Kit Chan)</td>\n",
       "      <td>許環良</td>\n",
       "      <td>林秋離</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>20130109</td>\n",
       "      <td>20170225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pZFNm5mDCLyr8uPAz3ScacFnUWzQLoxnDSTKv0PzCGY=</td>\n",
       "      <td>sZWiEZyCkvkanYHKgyA2L6+ZWNeMv8ZuZokBQgzlhdQ=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-library</td>\n",
       "      <td>1</td>\n",
       "      <td>216711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>孫盛希 (Shi Shi)</td>\n",
       "      <td>孫盛希</td>\n",
       "      <td>孫盛希</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>20150820</td>\n",
       "      <td>20170809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6iIGftYfxKLbJE6CtaBhDoBKAADRww0ca62XE0IYEf8=</td>\n",
       "      <td>95c7DAPEYsXPp72TZ4teA4ErdV1TNjajZcdk/if6AVM=</td>\n",
       "      <td>search</td>\n",
       "      <td>Artist more</td>\n",
       "      <td>top-hits-for-artist</td>\n",
       "      <td>0</td>\n",
       "      <td>334349</td>\n",
       "      <td>458</td>\n",
       "      <td>周杰倫 (Jay Chou)</td>\n",
       "      <td>周杰倫</td>\n",
       "      <td>周杰倫</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>20160124</td>\n",
       "      <td>20170930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  \\\n",
       "0  Z75En2y0vBrKTwJ3taDYLpu/xDQLnYcEGKgxaqVtPwM=   \n",
       "1  S1GUmx833Bi+TTIX7/gLutzwqFssO/fYQKfeoMsVKMI=   \n",
       "2  1fe9d48tkl74qwJJ3UGq5wJG2NEBoRI36YMYqTrTplo=   \n",
       "3  pZFNm5mDCLyr8uPAz3ScacFnUWzQLoxnDSTKv0PzCGY=   \n",
       "4  6iIGftYfxKLbJE6CtaBhDoBKAADRww0ca62XE0IYEf8=   \n",
       "\n",
       "                                        song_id source_system_tab  \\\n",
       "0  kThrcfiM7bay5gCTGaV8vkS7S1eDJAduRy08b8NzQa4=        my library   \n",
       "1  uwGAfDt1trs7aTxUM5DPYRtalQY/IPszFbRPgayilDQ=          discover   \n",
       "2  /56EZoEb7TAm0G8GLJpA2Uzgg6QiJcYDwvI08I+w8JA=        my library   \n",
       "3  sZWiEZyCkvkanYHKgyA2L6+ZWNeMv8ZuZokBQgzlhdQ=        my library   \n",
       "4  95c7DAPEYsXPp72TZ4teA4ErdV1TNjajZcdk/if6AVM=            search   \n",
       "\n",
       "    source_screen_name          source_type  target  song_length genre_ids  \\\n",
       "0  Local playlist more       local-playlist       0       231758       465   \n",
       "1               Search                 song       0       263941       458   \n",
       "2  Local playlist more        local-library       1       272811       465   \n",
       "3  Local playlist more        local-library       1       216711       NaN   \n",
       "4          Artist more  top-hits-for-artist       0       334349       458   \n",
       "\n",
       "         artist_name   composer  lyricist  language  city  bd  gender  \\\n",
       "0  小樂 (吳思賢) (Ben Wu)        范瑋琪       王雅君       3.0     1   0     NaN   \n",
       "1  楊丞琳 (Rainie Yang)  Xiao-Leng  Ai-Li-Si       3.0     5   0     NaN   \n",
       "2     陳潔儀 (Kit Chan)        許環良       林秋離       3.0     4  26  female   \n",
       "3      孫盛希 (Shi Shi)        孫盛希       孫盛希       3.0     5  18  female   \n",
       "4     周杰倫 (Jay Chou)        周杰倫       周杰倫       3.0    13  23  female   \n",
       "\n",
       "   registered_via  registration_init_time  expiration_date  \n",
       "0               7                20130328         20170930  \n",
       "1               9                20150801         20170918  \n",
       "2               3                20130109         20170225  \n",
       "3               3                20150820         20170809  \n",
       "4               4                20160124         20170930  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the columns with a lot of missing values and also registration, expiration dates and song_length, just for simplification\n",
    "\n",
    "I did it just to save time on data cleaning and preparation. These columns can easily be included if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['lyricist','gender','registration_init_time','expiration_date','song_length'],axis=1,inplace=True)#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename bd to age. Cleaning age column from unrealistic values, replacing them with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'bd':'age'},inplace=True)\n",
    "\n",
    "df['age'].where(((df['age']<75) & (df['age']>10)),0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much data is missing from the age column in %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.93412313281102"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'][df['age']==0].count()/df['age'].count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating column that indicates if the age is missing (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['missing_age']=(df['age']==0).astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list all column that will be treated as categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col=['msno', 'song_id', 'source_system_tab', 'source_screen_name',\n",
    "        'source_type', 'genre_ids', 'artist_name', 'composer',\n",
    "        'language','registered_via','city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 73774 entries, 0 to 73773\n",
      "Data columns (total 14 columns):\n",
      "msno                  73774 non-null object\n",
      "song_id               73774 non-null object\n",
      "source_system_tab     73541 non-null object\n",
      "source_screen_name    69675 non-null object\n",
      "source_type           73579 non-null object\n",
      "target                73774 non-null int64\n",
      "genre_ids             72586 non-null object\n",
      "artist_name           73774 non-null object\n",
      "composer              57063 non-null object\n",
      "language              73773 non-null float64\n",
      "city                  73774 non-null int64\n",
      "age                   73774 non-null int64\n",
      "registered_via        73774 non-null int64\n",
      "missing_age           73774 non-null int8\n",
      "dtypes: float64(1), int64(4), int8(1), object(8)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1412df2a-ea7b-4130-b4cb-91026afca736",
    "_uuid": "631e06cba7993a2315daec41d19f2dae5d2a680f"
   },
   "source": [
    "#### Convert columns to categorical and replace NA with additional category 'unknown'. Add this new category to all categorical columns even if they have no NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "1412df2a-ea7b-4130-b4cb-91026afca736",
    "_uuid": "631e06cba7993a2315daec41d19f2dae5d2a680f"
   },
   "outputs": [],
   "source": [
    "for col in cat_col:\n",
    "    df[col] = df[col].astype('category')\n",
    "    if 'unknown' not in df[col].cat.categories:\n",
    "        df[col].cat.add_categories(['unknown'],inplace=True)\n",
    "    df[col].fillna(value='unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(df,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dict of categories mapping to category index for using during serving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_map={col:dict(zip(train[col].cat.categories, train[col].cat.codes))\\\n",
    "               for col in train.select_dtypes(include=['category']).columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dict for serving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat_map.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_map_filename = \"cat_map.pkl\"\n",
    "joblib.dump(categories_map, cat_map_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating target values for model prediction and removing target from the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttnnn\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "YY_train=np.array(train['target'])\n",
    "YY_test =np.array(test['target'])\n",
    "\n",
    "train.drop('target',inplace=True,axis=1)\n",
    "test.drop('target',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the test set categories that were not present in the train set should be set to 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttnnn\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "for col in test.select_dtypes(include=['category']).columns:\n",
    "    for cat in test[col].cat.categories:\n",
    "        if not (cat in train[col].cat.categories):\n",
    "            test[col].cat.remove_categories(cat)\n",
    "    test[col].fillna('unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create datasets as dictionary of numpy arrays with the right dimentions for training and testing for categorical and binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data for prediction\n",
    "XX_train={}\n",
    "for col in train.select_dtypes(include=['category']).columns:\n",
    "    XX_train[col]=np.expand_dims(np.array(train[col].cat.codes),axis=-1)\n",
    "\n",
    "for col in train.select_dtypes(include=['int8']).columns:\n",
    "    XX_train[col]=np.expand_dims(np.array(train[col].values),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_test={}\n",
    "for col in test.select_dtypes(include=['category']).columns:\n",
    "    test[col].cat.remove_categories\n",
    "    XX_test[col]=np.expand_dims(np.array(test[col].cat.codes),axis=-1)\n",
    "\n",
    "for col in test.select_dtypes(include=['int8']).columns:\n",
    "    XX_test[col]=np.expand_dims(np.array(test[col].values),axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical columns should be scaled. In present case we have just one numerical column 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_age=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create and scale age column in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_age=MinMaxScaler()\n",
    "\n",
    "XX_train['age'] = np.array(train['age'],dtype='float32')\n",
    "\n",
    "XX_train['age']=np.expand_dims(XX_train['age'],axis=-1)\n",
    "\n",
    "XX_train['age']=scaler_age.fit_transform(XX_train['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same for the testing data except scaler not to be fitted, to avoid data leaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_test['age'] = np.array(test['age'],dtype='float32')\n",
    "\n",
    "XX_test['age']=np.expand_dims(XX_test['age'],axis=-1)\n",
    "\n",
    "XX_test['age']=scaler_age.transform(XX_test['age'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save scaler to use it later for serving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_filename = \"scaler.pkl\"\n",
    "joblib.dump(scaler_age, scaler_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dictionary containing the numbers of categories in each column and a list of numerical features. It will be necessary for building the model later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dim_train={col:len(train[col].cat.categories) for col in train.select_dtypes(include=['category']).columns}\n",
    "cont_features=[col for col in train.select_dtypes(exclude=['category']).columns if col != 'id'] #and col!='target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining inputs for categorical data as dictionary of the form {featute: input_tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cat_inputs(cat_dim):\n",
    "    return {feature:Input((1,),name=feature,dtype='int64') for feature in cat_dim}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_inputs=build_cat_inputs(cat_dim_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining inputs for nmerical data in the same form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cont_inputs(cont_features):\n",
    "    return {feature:Input((1,),name=feature,dtype='float32') for feature in cont_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_inputs=build_cont_inputs(cont_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating function that builds the model\n",
    "\n",
    "This function returns the model and the list of features which is necessary to organize data in inputs in correct order. I've used the functional API of keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cat_inputs,cont_inputs,cat_dim):\n",
    "    \n",
    "    inputs=cat_inputs.copy()\n",
    "    inputs.update(cont_inputs)\n",
    "    \n",
    "    #list of ordered features to define correct form of the input data\n",
    "    features=sorted(list(inputs.keys()))\n",
    "\n",
    "    vec=cont_inputs.copy()\n",
    "    for key in cat_inputs.keys():\n",
    "        \n",
    "        # Embedding categorical values the embedding dimention is chosen to be number_of_category/2, but not bigger than 50\n",
    "        vec[key]=Embedding(cat_dim[key],min(cat_dim[key]//2,50))(cat_inputs[key])\n",
    "        \n",
    "        # Reshape the embedding vectors to bring them to standard shape\n",
    "        vec[key]=Lambda(lambda x: K.squeeze(x,axis=1))(vec[key])\n",
    "\n",
    "    # Concatinate all numerical inputs and embedding vectors\n",
    "    x=Concatenate(axis=-1)([vec[feature] for feature in features])\n",
    "    \n",
    "    # Stack of fully connected layers with BatchNorm and Dropout in between\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(128,activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(128,activation='relu')(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(128,activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(128,activation='relu')(x)\n",
    "    out=Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    model=Model(inputs=[inputs[feature] for feature in features], outputs=[out])\n",
    "        \n",
    "    return model,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel,features=build_model(cat_inputs,cont_inputs,cat_dim_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "artist_name (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "city (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "composer (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "genre_ids (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "language (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msno (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "registered_via (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "song_id (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_screen_name (InputLayer) (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_system_tab (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_type (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 50)        332150      artist_name[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 11)        242         city[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 50)        500350      composer[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 50)        11500       genre_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 5)         55          language[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 50)        939400      msno[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 3)         18          registered_via[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        1371500     song_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 9)         171         source_screen_name[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 4)         36          source_system_tab[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 6)         78          source_type[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 50)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 11)           0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 50)           0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 50)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 5)            0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "missing_age (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 50)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 3)            0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 9)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 6)            0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 290)          0           age[0][0]                        \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 missing_age[0][0]                \n",
      "                                                                 lambda[0][0]                     \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 290)          1160        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          37248       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          16512       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            129         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,244,085\n",
      "Trainable params: 3,243,249\n",
      "Non-trainable params: 836\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organizing training and testing datasets in correctly ordered lists for feeding into model.\n",
    "\n",
    "That's where the list of features we got together with the model is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[XX_train[feature] for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[XX_test[feature] for feature in features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use early stopping to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_back=keras.callbacks.EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel.compile(opt,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttnnn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66396 samples, validate on 7378 samples\n",
      "Epoch 1/5\n",
      "66396/66396 [==============================] - 31s 467us/step - loss: 0.6892 - acc: 0.5669 - val_loss: 0.6665 - val_acc: 0.6031\n",
      "Epoch 2/5\n",
      "66396/66396 [==============================] - 29s 438us/step - loss: 0.6483 - acc: 0.6297 - val_loss: 0.6471 - val_acc: 0.6279\n",
      "Epoch 3/5\n",
      "66396/66396 [==============================] - 31s 463us/step - loss: 0.5765 - acc: 0.6973 - val_loss: 0.6556 - val_acc: 0.6179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11b8d3d4978>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmodel.fit(X_train,YY_train,batch_size=128,epochs=5,validation_data=(XX_test,YY_test),callbacks=[call_back])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the performanse on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels=np.floor(mmodel.predict(X_test)+1./2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "ba0144a2-a2fd-470e-9235-b3706d04c164",
    "_uuid": "ce9eb38a6602c87ddf9e757dd9e2401ae814f909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.56      0.59      3655\n",
      "          1       0.61      0.68      0.64      3723\n",
      "\n",
      "avg / total       0.62      0.62      0.62      7378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(YY_test, predict_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel.save('music_rec.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the features list for serving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_filename = \"features.pkl\"\n",
    "joblib.dump(features, features_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if saved model can be downloaded without problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=load_model('music_rec.hdf5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels=np.floor(model1.predict(X_test)+1./2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.56      0.59      3655\n",
      "          1       0.61      0.68      0.64      3723\n",
      "\n",
      "avg / total       0.62      0.62      0.62      7378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(YY_test, predict_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save uncompiled model to get rid of training information and save space (the model file size is reduced from 38mb to 12mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('music_rec.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
