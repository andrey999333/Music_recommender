{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "99eb1258-c71a-4b82-8e59-982d15f09fd0",
    "_uuid": "9238ff111736f6dafa907a02fed5bf5f59e4fc27"
   },
   "source": [
    "# Music Recommendation\n",
    "\n",
    "In this notebook I create and train the model for this dataset https://www.kaggle.com/c/kkbox-music-recommendation-challenge/data. The aim is to predict if a user will listen a song for a second time within a month after the first time. Based on this information a recommendation system can be built.\n",
    "\n",
    "#### The structure of the data:\n",
    "\n",
    "**train.csv**\n",
    "\n",
    "msno: user id\n",
    "song_id: song id\n",
    "source_system_tab: the name of the tab where the event was triggered. System tabs are used to categorize KKBOX mobile apps functions. For example, tab my library contains functions to manipulate the local storage, and tab search contains functions relating to search.\n",
    "source_screen_name: name of the layout a user sees.\n",
    "source_type: an entry point a user first plays music on mobile apps. An entry point could be album, online-playlist, song .. etc.\n",
    "target: this is the target variable. target=1 means there are recurring listening event(s) triggered within a month after the user’s very first observable listening event, target=0 otherwise .\n",
    "\n",
    "**songs.csv**\n",
    "\n",
    "The songs. Note that data is in unicode.\n",
    "\n",
    "song_id\n",
    "song_length: in ms\n",
    "genre_ids: genre category. Some songs have multiple genres and they are separated by |\n",
    "artist_name\n",
    "composer\n",
    "lyricist\n",
    "language\n",
    "\n",
    "**members.csv**\n",
    "\n",
    "user information.\n",
    "\n",
    "msno\n",
    "city\n",
    "bd: age. Note: this column has outlier values, please use your judgement.\n",
    "gender\n",
    "registered_via: registration method\n",
    "registration_init_time: format %Y%m%d\n",
    "expiration_date: format %Y%m%d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3cb501c4-dadc-4c3d-9034-dae9f36cfca1",
    "_uuid": "8401fb3bb4c7a53a8c58e48db4113d1d402a8111"
   },
   "source": [
    "#### Load Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "3cb501c4-dadc-4c3d-9034-dae9f36cfca1",
    "_uuid": "8401fb3bb4c7a53a8c58e48db4113d1d402a8111"
   },
   "outputs": [],
   "source": [
    "#1 for data preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#2 for building a model \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "083ab3c8-e2fc-472b-af26-fedf97c82dbc",
    "_uuid": "ed268cdb9426fa20e5b4e523b2c14fe9ca6a7741"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "083ab3c8-e2fc-472b-af26-fedf97c82dbc",
    "_uuid": "ed268cdb9426fa20e5b4e523b2c14fe9ca6a7741"
   },
   "source": [
    "#### Downloading data. 1% of Data is used to speed up execution. Can also be run on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "323c09d3-4908-478a-abc9-8d7be6669620",
    "_uuid": "9a273952dd0ac2715f48aa16a90278bba6021a1e"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# 1% sample of items\n",
    "df = df.sample(frac=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join data of songs, members and events (train) into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "133c555c-7927-4e60-ad75-f2fabb82b948",
    "_uuid": "e35704b25cc37bbc9e231e681cbd627a95aeadbc"
   },
   "outputs": [],
   "source": [
    "# Load and join songs data\n",
    "songs = pd.read_csv('./data/songs.csv')\n",
    "df = pd.merge(df, songs, on='song_id', how='left')\n",
    "del songs\n",
    "\n",
    "# Load and join songs data\n",
    "members = pd.read_csv('./data/members.csv')\n",
    "df = pd.merge(df, members, on='msno', how='left')\n",
    "del members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check how much data is missing in each column in %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "941e45d6-2ef6-499c-9bef-240e9f309701",
    "_uuid": "c2b3d2b26bfa4e8186203b3a85b49dcf8b5404ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msno                       0.000000\n",
       "song_id                    0.000000\n",
       "source_system_tab          0.342755\n",
       "source_screen_name         5.960588\n",
       "source_type                0.293646\n",
       "target                     0.000000\n",
       "song_length                0.002711\n",
       "genre_ids                  1.548542\n",
       "artist_name                0.002711\n",
       "composer                  29.056749\n",
       "lyricist                  75.193541\n",
       "language                   0.005422\n",
       "city                       0.000000\n",
       "bd                         0.000000\n",
       "gender                    66.431295\n",
       "registered_via             0.000000\n",
       "registration_init_time     0.000000\n",
       "expiration_date            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()/df.count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check how the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_type</th>\n",
       "      <th>target</th>\n",
       "      <th>song_length</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>composer</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>language</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>expiration_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2FvE4x+hefwL4evbgNGNCng13c1MkP3PHocNtU91qU=</td>\n",
       "      <td>0FbtVUWrMLk0Gl9WNMwwJbKTVmvzyt7aJUM532uvsps=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>225048.0</td>\n",
       "      <td>921</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>Robert Lopez| Kristen Anderson-Lopez</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>20100728</td>\n",
       "      <td>20171218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zRunn9KBc0bXEkd7vQKIapskqhhKz9jK2VOIOScBPXI=</td>\n",
       "      <td>8esjTau8b/ZNlndJ1vRAvBLKjGcReGFVCXbS997tUZg=</td>\n",
       "      <td>listen with</td>\n",
       "      <td>Others profile more</td>\n",
       "      <td>song</td>\n",
       "      <td>0</td>\n",
       "      <td>274552.0</td>\n",
       "      <td>465</td>\n",
       "      <td>蔡淳佳 (Joi Chua)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20161230</td>\n",
       "      <td>20171101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abQj3Jp4gyZQtOovZdZeXgPS9uPQhDLJK2EohLAEqf0=</td>\n",
       "      <td>nPMmTq6c5pA9WMHXRJVjZxtnm3l06GjTHWCAo2IG5JI=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-library</td>\n",
       "      <td>1</td>\n",
       "      <td>376721.0</td>\n",
       "      <td>465</td>\n",
       "      <td>Namie Amuro (安室奈美恵)</td>\n",
       "      <td>TETSUYA KOMURO</td>\n",
       "      <td>TETSUYA KOMURO</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>20141210</td>\n",
       "      <td>20180327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3kfP6l/SfLV7vhNmKMXmw2WWbJ6YHAekgyJtBGCzPSo=</td>\n",
       "      <td>xNnUQnABeXxUF59mngBVVcBpGiBvkFKIHR3Hkj+rGW0=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-library</td>\n",
       "      <td>1</td>\n",
       "      <td>266518.0</td>\n",
       "      <td>458</td>\n",
       "      <td>蕭閎仁</td>\n",
       "      <td>蕭閎仁</td>\n",
       "      <td>蕭閎仁+林尚德</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20131220</td>\n",
       "      <td>20170930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u3g6JVGfbP3kxvJrdUX4jDyF8+eEDl4CE7k2Mpn+/As=</td>\n",
       "      <td>zHqZ07gn+YvF36FWzv9+y8KiCMhYhdAUS+vSIKY3UZY=</td>\n",
       "      <td>discover</td>\n",
       "      <td>Discover Feature</td>\n",
       "      <td>online-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>189361.0</td>\n",
       "      <td>1616|1609</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>Alan Walker| Jesper Borgen| Anders Froen| Gunn...</td>\n",
       "      <td>Alan Walker| Jesper Borgen| Anders Froen| Gunn...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>20111127</td>\n",
       "      <td>20170710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  \\\n",
       "0  R2FvE4x+hefwL4evbgNGNCng13c1MkP3PHocNtU91qU=   \n",
       "1  zRunn9KBc0bXEkd7vQKIapskqhhKz9jK2VOIOScBPXI=   \n",
       "2  abQj3Jp4gyZQtOovZdZeXgPS9uPQhDLJK2EohLAEqf0=   \n",
       "3  3kfP6l/SfLV7vhNmKMXmw2WWbJ6YHAekgyJtBGCzPSo=   \n",
       "4  u3g6JVGfbP3kxvJrdUX4jDyF8+eEDl4CE7k2Mpn+/As=   \n",
       "\n",
       "                                        song_id source_system_tab  \\\n",
       "0  0FbtVUWrMLk0Gl9WNMwwJbKTVmvzyt7aJUM532uvsps=        my library   \n",
       "1  8esjTau8b/ZNlndJ1vRAvBLKjGcReGFVCXbS997tUZg=       listen with   \n",
       "2  nPMmTq6c5pA9WMHXRJVjZxtnm3l06GjTHWCAo2IG5JI=        my library   \n",
       "3  xNnUQnABeXxUF59mngBVVcBpGiBvkFKIHR3Hkj+rGW0=        my library   \n",
       "4  zHqZ07gn+YvF36FWzv9+y8KiCMhYhdAUS+vSIKY3UZY=          discover   \n",
       "\n",
       "    source_screen_name      source_type  target  song_length  genre_ids  \\\n",
       "0  Local playlist more   local-playlist       1     225048.0        921   \n",
       "1  Others profile more             song       0     274552.0        465   \n",
       "2  Local playlist more    local-library       1     376721.0        465   \n",
       "3  Local playlist more    local-library       1     266518.0        458   \n",
       "4     Discover Feature  online-playlist       1     189361.0  1616|1609   \n",
       "\n",
       "           artist_name                                           composer  \\\n",
       "0               Frozen               Robert Lopez| Kristen Anderson-Lopez   \n",
       "1       蔡淳佳 (Joi Chua)                                                NaN   \n",
       "2  Namie Amuro (安室奈美恵)                                     TETSUYA KOMURO   \n",
       "3                  蕭閎仁                                                蕭閎仁   \n",
       "4          Alan Walker  Alan Walker| Jesper Borgen| Anders Froen| Gunn...   \n",
       "\n",
       "                                            lyricist  language  city  bd  \\\n",
       "0                                                NaN      52.0     5  47   \n",
       "1                                                NaN       3.0     9   0   \n",
       "2                                     TETSUYA KOMURO      17.0     5  31   \n",
       "3                                            蕭閎仁+林尚德       3.0     1   0   \n",
       "4  Alan Walker| Jesper Borgen| Anders Froen| Gunn...      52.0    15  32   \n",
       "\n",
       "  gender  registered_via  registration_init_time  expiration_date  \n",
       "0   male               9                20100728         20171218  \n",
       "1    NaN               4                20161230         20171101  \n",
       "2    NaN               9                20141210         20180327  \n",
       "3    NaN               7                20131220         20170930  \n",
       "4   male               9                20111127         20170710  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the columns with a lot of missing values and also registration, expiration dates and song_length, just for simplification\n",
    "\n",
    "I did it just to save time on data cleaning and preparation. These columns can easily be included if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['lyricist','gender','registration_init_time','expiration_date','song_length'],axis=1,inplace=True)#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename bd to age. Cleaning age column from unrealistic values, replacing them with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'bd':'age'},inplace=True)\n",
    "\n",
    "df['age'].where(((df['age']<75) & (df['age']>10)),0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much data is missing from the age column in %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.74435437959173"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'][df['age']==0].count()/df['age'].count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating column that indicates if the age is missing (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['missing_age']=(df['age']==0).astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list all column that will be treated as categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col=['msno', 'song_id', 'source_system_tab', 'source_screen_name',\n",
    "        'source_type', 'genre_ids', 'artist_name', 'composer',\n",
    "        'language','registered_via','city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 73774 entries, 0 to 73773\n",
      "Data columns (total 14 columns):\n",
      "msno                  73774 non-null object\n",
      "song_id               73774 non-null object\n",
      "source_system_tab     73522 non-null object\n",
      "source_screen_name    69624 non-null object\n",
      "source_type           73558 non-null object\n",
      "target                73774 non-null int64\n",
      "genre_ids             72649 non-null object\n",
      "artist_name           73772 non-null object\n",
      "composer              57164 non-null object\n",
      "language              73770 non-null float64\n",
      "city                  73774 non-null int64\n",
      "age                   73774 non-null int64\n",
      "registered_via        73774 non-null int64\n",
      "missing_age           73774 non-null int8\n",
      "dtypes: float64(1), int64(4), int8(1), object(8)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1412df2a-ea7b-4130-b4cb-91026afca736",
    "_uuid": "631e06cba7993a2315daec41d19f2dae5d2a680f"
   },
   "source": [
    "#### Convert columns to categorical and replace NA with additional category 'unknown'. Add this new category to all categorical columns even if they have no NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "1412df2a-ea7b-4130-b4cb-91026afca736",
    "_uuid": "631e06cba7993a2315daec41d19f2dae5d2a680f"
   },
   "outputs": [],
   "source": [
    "for col in cat_col:\n",
    "    df[col] = df[col].astype('category')\n",
    "    if 'unknown' not in df[col].cat.categories:\n",
    "        df[col].cat.add_categories(['unknown'],inplace=True)\n",
    "    df[col].fillna(value='unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(df,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dict of categories mapping to category index for using during serving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_map={col:dict(zip(train[col].cat.categories, train[col].cat.codes))\\\n",
    "               for col in train.select_dtypes(include=['category']).columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dict for serving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat_map.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_map_filename = \"cat_map.pkl\"\n",
    "joblib.dump(categories_map, cat_map_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating target values for model prediction and removing target from the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttnnn\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "YY_train=np.array(train['target'])\n",
    "YY_test =np.array(test['target'])\n",
    "\n",
    "train.drop('target',inplace=True,axis=1)\n",
    "test.drop('target',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the test set categories that were not present in the train set should be set to 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttnnn\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "for col in test.select_dtypes(include=['category']).columns:\n",
    "    for cat in test[col].cat.categories:\n",
    "        if not (cat in train[col].cat.categories):\n",
    "            test[col].cat.remove_categories(cat)\n",
    "    test[col].fillna('unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create datasets as dictionary of numpy arrays with the right dimentions for training and testing for categorical and binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data for prediction\n",
    "XX_train={}\n",
    "for col in train.select_dtypes(include=['category']).columns:\n",
    "    XX_train[col]=np.expand_dims(np.array(train[col].cat.codes),axis=-1)\n",
    "\n",
    "for col in train.select_dtypes(include=['int8']).columns:\n",
    "    XX_train[col]=np.expand_dims(np.array(train[col].values),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_test={}\n",
    "for col in test.select_dtypes(include=['category']).columns:\n",
    "    XX_test[col]=np.expand_dims(np.array(test[col].cat.codes),axis=-1)\n",
    "\n",
    "for col in test.select_dtypes(include=['int8']).columns:\n",
    "    XX_test[col]=np.expand_dims(np.array(test[col].values),axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical columns should be scaled. In present case we have just one numerical column 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_age=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create and scale age column in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_age=MinMaxScaler()\n",
    "\n",
    "XX_train['age'] = np.array(train['age'],dtype='float32')\n",
    "\n",
    "XX_train['age']=np.expand_dims(XX_train['age'],axis=-1)\n",
    "\n",
    "XX_train['age']=scaler_age.fit_transform(XX_train['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same for the testing data except scaler not to be fitted, to avoid data leaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_test['age'] = np.array(test['age'],dtype='float32')\n",
    "\n",
    "XX_test['age']=np.expand_dims(XX_test['age'],axis=-1)\n",
    "\n",
    "XX_test['age']=scaler_age.transform(XX_test['age'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save scaler to use it later for serving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_filename = \"scaler.pkl\"\n",
    "joblib.dump(scaler_age, scaler_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dictionary containing the numbers of categories in each column and a list of numerical features. It will be necessary for building the model later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dim_train={col:len(train[col].cat.categories) for col in train.select_dtypes(include=['category']).columns}\n",
    "cont_features=[col for col in train.select_dtypes(exclude=['category']).columns if col != 'id'] #and col!='target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining inputs for categorical data as dictionary of the form {featute: input_tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cat_inputs(cat_dim):\n",
    "    return {feature:Input((1,),name=feature,dtype='int64') for feature in cat_dim}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_inputs=build_cat_inputs(cat_dim_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining inputs for nmerical data in the same form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cont_inputs(cont_features):\n",
    "    return {feature:Input((1,),name=feature,dtype='float32') for feature in cont_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_inputs=build_cont_inputs(cont_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating function that builds the model\n",
    "\n",
    "This function returns the model and the list of features which is necessary to organize data in inputs in correct order. I've used the functional API of keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cat_inputs,cont_inputs,cat_dim):\n",
    "    \n",
    "    inputs=cat_inputs.copy()\n",
    "    inputs.update(cont_inputs)\n",
    "    \n",
    "    #list of ordered features to define correct form of the input data\n",
    "    features=sorted(list(inputs.keys()))\n",
    "\n",
    "    vec=cont_inputs.copy()\n",
    "    for key in cat_inputs.keys():\n",
    "        \n",
    "        # Embedding categorical values the embedding dimention is chosen to be number_of_category/2, but not bigger than 50\n",
    "        vec[key]=Embedding(cat_dim[key],min(cat_dim[key]//2,50))(cat_inputs[key])\n",
    "        \n",
    "        # Reshape the embedding vectors to get rid of extra dimension and unify the shape of all vectors\n",
    "        vec[key]=Lambda(lambda x: K.squeeze(x,axis=1))(vec[key])\n",
    "\n",
    "    # Concatinate all numerical inputs and embedding vectors\n",
    "    x=Concatenate(axis=-1)([vec[feature] for feature in features])\n",
    "    \n",
    "    # Stack of fully connected layers with BatchNorm and Dropout in between\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(128,activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(128,activation='relu')(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(128,activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(128,activation='relu')(x)\n",
    "    out=Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    model=Model(inputs=[inputs[feature] for feature in features], outputs=[out])\n",
    "        \n",
    "    return model,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel,features=build_model(cat_inputs,cont_inputs,cat_dim_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "artist_name (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "city (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "composer (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "genre_ids (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "language (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msno (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "registered_via (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "song_id (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_screen_name (InputLayer) (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_system_tab (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_type (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 50)        327400      artist_name[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 11)        242         city[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 50)        498100      composer[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 50)        11650       genre_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 5)         55          language[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 50)        937050      msno[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 3)         18          registered_via[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        1368050     song_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 9)         171         source_screen_name[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 4)         36          source_system_tab[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 6)         78          source_type[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 50)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 11)           0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 50)           0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 50)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 5)            0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "missing_age (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 50)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 3)            0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 9)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 6)            0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 290)          0           age[0][0]                        \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 missing_age[0][0]                \n",
      "                                                                 lambda[0][0]                     \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 290)          1160        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          37248       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          16512       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            129         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,231,435\n",
      "Trainable params: 3,230,599\n",
      "Non-trainable params: 836\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organizing training and testing datasets in correctly ordered lists for feeding into model.\n",
    "\n",
    "That's where the list of features we got together with the model is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[XX_train[feature] for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[XX_test[feature] for feature in features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use early stopping to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_back=keras.callbacks.EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel.compile(opt,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttnnn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66396 samples, validate on 7378 samples\n",
      "Epoch 1/5\n",
      "66396/66396 [==============================] - 40s 599us/step - loss: 0.6854 - acc: 0.5729 - val_loss: 0.6597 - val_acc: 0.6189\n",
      "Epoch 2/5\n",
      "66396/66396 [==============================] - 37s 563us/step - loss: 0.6408 - acc: 0.6383 - val_loss: 0.6457 - val_acc: 0.6332\n",
      "Epoch 3/5\n",
      "66396/66396 [==============================] - 38s 566us/step - loss: 0.5565 - acc: 0.7165 - val_loss: 0.6600 - val_acc: 0.6175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df4b095390>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmodel.fit(X_train,YY_train,batch_size=128,epochs=5,validation_data=(XX_test,YY_test),callbacks=[call_back])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the performanse on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels=np.floor(mmodel.predict(X_test)+1./2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "ba0144a2-a2fd-470e-9235-b3706d04c164",
    "_uuid": "ce9eb38a6602c87ddf9e757dd9e2401ae814f909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.58      0.60      3669\n",
      "          1       0.61      0.65      0.63      3709\n",
      "\n",
      "avg / total       0.62      0.62      0.62      7378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(YY_test, predict_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel.save('music_rec.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the features list for serving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_filename = \"features.pkl\"\n",
    "joblib.dump(features, features_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if saved model can be downloaded without problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=load_model('music_rec.hdf5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels=np.floor(model1.predict(X_test)+1./2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.58      0.60      3669\n",
      "          1       0.61      0.65      0.63      3709\n",
      "\n",
      "avg / total       0.62      0.62      0.62      7378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(YY_test, predict_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save uncompiled model to get rid of training information and save space (the model file size is reduced from 38mb to 12mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('music_rec.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
